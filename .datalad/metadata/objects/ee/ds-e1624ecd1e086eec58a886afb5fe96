{
"@context":
{
"@vocab":
"http://docs.datalad.org/schema_v2.0.json"
},
"bids":
{
"@context":
{
"age(years)":
{
"@id":
"pato:0000011",
"description":
"age of a sample (organism) at the time of data acquisition in years",
"unit":
"uo:0000036",
"unit_label":
"year"
},
"bids":
{
"@id":
"http://bids.neuroimaging.io/bids_spec1.0.0.pdf#",
"description":
"ad-hoc vocabulary for the Brain Imaging Data Structure (BIDS) standard",
"type":
"http://purl.org/dc/dcam/VocabularyEncodingScheme"
}
},
"BIDSVersion":
"1.0.0",
"HowToAcknowledge":
"In addition to any citation requirements in the dataset summary please use the following to cite this dataset: 'This data was obtained from the OpenfMRI database. Its accession number is ds000205'",
"author":
[
"Jongwan Kim",
"Jing Wang",
"Svetlana V. Shinkareva",
"Douglas H. Wedell"
],
"conformsto":
"http://bids.neuroimaging.io/bids_spec1.0.0.pdf",
"description":
"﻿Data acquisition methods have been described in detail in Kim et al. (2016, PLoS ONE), but we outline them here and provide file information for clarity and ease of use.\n\n\n\r\n\r\n————————————————————————————————Materials\n————————————————————————————————\n\n\r\nParticipants viewed affect-eliciting audiovisual clips that varied on levels of valence and arousal. Eight stimuli were selected for each affective category corresponding to each of the four quadrants of the affective space: high arousal-negative valence (HN), low arousal-negative valence (LN), low arousal-positive valence (LP), and high arousal-positive valence (HP). \r\n\r\n————————————————————————————————\nBOLD fMRI DATA\n————————————————————————————————\r\nMRI data were acquired on a Siemens Magnetom Trio 3.0T whole-body scanner (Siemens, Erlangen, Germany) at the McCausland Center for Brain Imaging at the University of South Carolina. The functional images were acquired using a single-shot echo-planar imaging pulse sequence (TR = 2200ms, TE = 35ms, 90° flip angle) with a 12-channel head coil. Thirty-six 3 mm thick oblique-axial slices were imaged in interleaved scanning order with no gap. The acquisition matrix was 64×64 with 3×3×3 mm voxels.  Functional data was acquired using a slow event-related design in two scanning sessions (two runs for each session). High-resolution whole-brain anatomical images were acquired using a standard T1-weighted 3D MP-RAGE protocol (TR= 2250 ms, TE= 4.18 ms, FOV= 256 mm, flip angle= 9°, voxel size=1×1×1 mm) to facilitate normalization of the functional data.  \r\nData processing and statistical analyses were performed in MATLAB environment using standard procedures in Statistical Parametric Mapping software (SPM 8, Wellcome Department of Cognitive Neurology, London, UK). The data were corrected for motion and linear trend. Structural data were segmented into white and gray matter to facilitate the normalization. Functional and anatomical images were co-registered and spatially normalized into the standard Montreal Neurological Institute (MNI) space based on T1-derived normalization parameters. \r\nMain experiment To improve signal-to-noise ratio, the time-series data for each voxel were fit using GLMdenoise, a technique successfully used in MVPA and other applications [54, 55]. GLMdenoise used the four affective categories to estimate regressors of no interest.  Notably the procedure was blind to valence and arousal categories, and thus did not bias the results when comparing across combined categories (i.e., positive versus negative valence or high versus low arousal). Furthermore, to control for possible confounds arising from lower level features of the stimuli, five lower level feature components were regressed out as covariates of no interest together with six head motion parameter estimates. We used principal components to reduce the number of regressors, while keeping most of the variability in the data.The residuals from this analysis were used for all further analyses. The percent signal change (PSC) relative to the average activity in a voxel was computed for each voxel in every volume from the residuals. The mean PSC of two volumes, offset 4.4s from the stimulus onset (to account for the delay in hemodynamic response), was used as the input for further analyses. Data for each condition were standardized across voxels to have zero mean and unit variance. \r\n \r\n\r\n\n\n————————————————————————————————\nFUNCTIONAL LOCALIZER\n————————————————————————————————\n\r\nAreas responsive to naturalistic audiovisual presentation were identified in a separate localizer session for each participant. There were four experimental conditions: baseline, auditory (beep), dynamic visual (checkerboard), and a combined naturalistic audiovisual condition (audiovisual). Additionally, the functional localizer contained two other conditions that were not part of the present experiment. The conditions were presented in a block design with each block lasting 12s (Fig 2A). Baseline condition consisted of a black screen with a white fixation cross shown in the center of the screen and background noise. During an auditory condition, designed to localize primary auditory cortex, a binaural sine tone of 1,000 Hz pulsating at 6 Hz was presented. During a dynamic visual condition, designed to localize primary visual areas, there were 12s of high-contrast flickering checkerboard reversals, 200ms per cycle. During a naturalistic audiovisual condition, four 3s audiovisual clips sampled from the four affective quadrants were played back to back. There were eight runs in the localizer scan and each run consisted of six conditions presented in a pseudo randomized order such that the same condition was not presented twice in a row for the two subsequent runs. There were a total of 48 blocks resulting in 273 acquired volumes.\r\n\r\n\n\n\n\n————————————————————————————————\nPUBLICATIONS\n————————————————————————————————\n\n\r\nJongwan Kim, Jing Wang, Douglas H. Wedell, Svetlana V. Shinkareva (2016) “Identifying Core Affect in Individuals from fMRI Responses to Dynamic Naturalistic Audiovisual Stimuli” PLoS One",
"license":
"PDDL",
"name":
"Affective Videos"
},
"datalad_core":
{
"@id":
"18003eae-7232-11e6-885a-002590f97d84",
"ispartof":
{
"@id":
"14114028-7d08-11e6-9ce4-002590f97d84",
"type":
"dataset"
},
"refcommit":
"6c6f8f5ddcf9fc07e2b575233a71e5b187ea4249"
},
"datalad_unique_content_properties":
{
"bids":
{
"EchoTime":
[
0.00418,
0.035
],
"FlipAngle":
[
9,
90
],
"MagneticFieldStrength":
[
3
],
"Manufacturer":
[
"Siemens"
],
"ManufacturersModelName":
[
"Magnetom Trio"
],
"PulseSequenceType":
[
"MPRAGE",
"single-shot echo-planar"
],
"RepetitionTime":
[
2.2,
2.25
],
"TaskName":
[
"Functional localizer",
"Passive Viewing"
],
"modality":
[
"anat",
"func"
],
"run":
[
"1",
"2"
],
"subject":
[
{
"handedness":
"R",
"id":
"01"
},
{
"handedness":
"R",
"id":
"02"
},
{
"handedness":
"R",
"id":
"03"
},
{
"handedness":
"R",
"id":
"04"
},
{
"handedness":
"R",
"id":
"05"
},
{
"handedness":
"R",
"id":
"06"
},
{
"handedness":
"R",
"id":
"07"
},
{
"handedness":
"R",
"id":
"08"
},
{
"handedness":
"R",
"id":
"09"
},
{
"handedness":
"R",
"id":
"10"
},
{
"handedness":
"R",
"id":
"11"
}
],
"task":
[
"functionallocalizer",
"view"
],
"type":
[
"T1w",
"bold",
"events",
"participants"
]
},
"datalad_core":
{
"url":
null
},
"nifti1":
{
"cal_max":
null,
"cal_min":
null,
"datatype":
[
"float32"
],
"description":
[
"FreeSurfer May 13 2013"
],
"dim":
[
[
3,
256,
256,
192,
1,
1,
1,
1
],
[
4,
70,
70,
36,
285,
1,
1,
1
],
[
4,
70,
70,
36,
328,
1,
1,
1
],
[
4,
70,
70,
36,
365,
1,
1,
1
]
],
"freq_axis":
[
null
],
"intent":
[
"none"
],
"magic":
[
"n+1"
],
"phase_axis":
[
null
],
"pixdim":
[
[
-1.0,
1.0,
1.0,
1.0,
2.25,
1.0,
1.0,
1.0
],
[
-1.0,
3.0,
3.0,
3.0,
2.200000047683716,
1.0,
1.0,
1.0
]
],
"qform_code":
[
"scanner"
],
"sform_code":
[
"scanner"
],
"sizeof_hdr":
[
348
],
"slice_axis":
[
null
],
"slice_duration":
[
0.0
],
"slice_end":
[
0
],
"slice_order":
[
"unknown"
],
"slice_start":
[
0
],
"spatial_resolution(mm)":
[
[
1.0,
1.0,
1.0
],
[
3.0,
3.0,
3.0
]
],
"t_unit":
[
"second (uo:0000010)"
],
"temporal_spacing(s)":
[
2.200000047683716
],
"toffset":
[
0.0
],
"vox_offset":
[
0.0
],
"xyz_unit":
[
"millimiter (uo:0000016)"
]
}
},
"nifti1":
{
"@context":
{
"nifti1":
{
"@id":
"https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields#",
"description":
"Ad-hoc vocabulary for NIfTI1 header fields",
"type":
"http://purl.org/dc/dcam/VocabularyEncodingScheme"
},
"spatial_resolution(mm)":
{
"@id":
"idqa:0000162",
"description":
"spatial resolution in millimeter",
"unit":
"uo:0000016",
"unit_label":
"millimeter"
},
"temporal_spacing(s)":
{
"@id":
"idqa:0000213",
"description":
"temporal sample distance in 4D (in seconds)",
"unit":
"uo:0000010",
"unit_label":
"second"
}
}
},
"xmp":
{
"@context":
{}
}
}