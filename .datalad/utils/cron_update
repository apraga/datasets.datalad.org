#!/bin/bash

export PS1='$> '
#export PS4="> "
# Let's also log the time etc
export PS4='\n> # $(date +%T.%N)\n> '


set -eu

# A rudimentary update script which would take care about auto-updating on cron
# some selected set of the datasets.  This would help to outline use cases we
# would like to have addressed.

# Use our "centralized" environment.
source /home/yoh/proj/datalad/datalad-crawl-env/venvs/dev3/bin/activate

# Check externals
hash datalad
hash sem
hash chronic


cd "/mnt/btrfs/datasets/datalad/crawl"

# TODO: might want to just end up using singularity environment which to
# include here!
njobs=12


run1() {
    #echo "Running $@ under $PWD"
    chronic "$@"
}
export -f run1

runj() {
    #echo "Submitting $@ under $PWD"
    #sem -j$njobs "sleep 2; echo Done running $@"
    sem -j$njobs "$@"
    #echo "Done submitting $2"
}

doall() {
    func="$1"
    shift
    # TODO: parallelize this part
    for d in "$@"; do
       runj "$func" "$d";
    done
    sem --wait
    # And then save each at a time but without parallel since we would be
    # conflicting
    #for d in "$@"; do
    if [ "$#" -lt 5 ]; then
        msg="$@"
    else
        msg="$# paths"
    fi
    run1 datalad save -d . -m "Updates from looking at $msg" "$@"
    #done
}
export -f doall

datalad_update_ff_r() (
    msg="Fast forward $1 recursively"
    #-x echo "$msg"
    run1 datalad update -d "$1" --recursive --follow parentds --merge ff-only
    datalad save -d '.' -m "$msg" "$1"
)
export -f datalad_update_ff_r

datalad_crawl() (
    #-x echo "Crawl $1"
    cd "$1"
    run1 datalad crawl
)
export -f datalad_crawl

datalad_crawl_doall_update() (
    msg="Recrawl and update $1"
    #-x echo "$msg"
    set +x  # could be too many
    (
    cd "$1"
    run1 datalad crawl
    # Here using git module name which could differ from path
    subds=( $(datalad -f '{gitmodule_name}' subdatasets -r -R 1) )
    doall datalad_update_ff_r ${subds[*]}
    )
    set -x
    datalad save -d '.' -m "$msg" "$1"
)
export -f datalad_crawl_doall_update

set -x

datalad wtf -S datalad -S dependencies -S extensions

#
# Straightforward updates from other git repos
#
#doall 
datalad_update_ff_r \
    conp-dataset
    # might want only tags  templateflow \

# Here we crawl top but then update children in parallel
datalad_crawl_doall_update \
    openneuro

datalad diff -d . --from datalad-public/master --to HEAD -r 

# Publish since we got so far!
datalad publish --since= --to=datalad-public --missing=inherit -r

echo "done"
